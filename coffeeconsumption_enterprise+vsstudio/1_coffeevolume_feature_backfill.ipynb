{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoffeeVolume Prediction Demo\n",
    "This is a short demonstration of how you can use Hopsworks for creating a Machine Learning System that creates predictions. The hypothetical use case is that of a **barrista** who would want to predict how much coffee will be consumed in his bar, based on past trends and behaviour.\n",
    "\n",
    "![](https://blogstudio.s3.theshoppad.net/coffeeheroau/d4459a5d44905ff2cf3c245e7a931675.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80dec4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Code Library Imports </span>\n",
    "We are importing a `coffeevolume.py` and a `averages.py` script in this notebook, as we will use it later on to generate the historical data, plot it, and generate the second-order features for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d37094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from coffeevolume import generate_historical_data, to_wide_format, plot_historical_id\n",
    "from averages import calculate_second_order_features\n",
    "\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae4d6e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Coffee Consumption Data Import </span>\n",
    "\n",
    "In this demo, we will be generating synthetic coffee consumption data. For every day after a certain `START_DATE`, we will be generating a supposed volume of coffee that has been consumed.\n",
    "\n",
    "Therefore, let's define the `START_DATE` variable (format: %Y-%m-%d) which will indicate the start date for our coffee data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bee036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant START_DATE with a specific date (September 1, 2022)\n",
    "START_DATE = datetime.date(2023, 9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic historical data using the generate_historical_data function from START_DATE till current date\n",
    "data_generated = generate_historical_data(\n",
    "    START_DATE,  # Start date for data generation (September 1, 2023)\n",
    ")\n",
    "\n",
    "# Display the first 3 rows of the generated data\n",
    "data_generated.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8bacfa",
   "metadata": {},
   "source": [
    "Look at historical values for 1 and 2 IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e229269",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_historical_id([1,2], data_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e00ef",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\"> üëÆüèª‚Äç‚ôÇÔ∏è Coffee Volume data validation using Great Expectations</span>\n",
    "\n",
    "In order to make sure that the generated data is in the right format, we will be running the generated synthetic data through an \"Expectation Suite\" that is part of the \"Great Expectations\" framework (see [over here](https://github.com/great-expectations/great_expectations) for more info) that is part of [Hopsworks](www.hopsworks.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d644fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated historical data DataFrame to a Great Expectations DataFrame\n",
    "ge_coffeevolume_df = ge.from_pandas(data_generated)\n",
    "\n",
    "# Retrieve the expectation suite associated with the ge DataFrame\n",
    "expectation_suite_coffeevolume = ge_coffeevolume_df.get_expectation_suite()\n",
    "\n",
    "# Set the expectation suite name to \"coffeevolume_suite\"\n",
    "expectation_suite_coffeevolume.expectation_suite_name = \"coffeevolume_suite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the \"Expectation Suite\", we can add specific \"Expectations\" to that suite: every parameter that we generated will have comply with a specific expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expectation for the 'id' column values to be between 0 and 5000\n",
    "expectation_suite_coffeevolume.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"id\",\n",
    "            \"min_value\": 0,\n",
    "            \"max_value\": 5000,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add expectation for the 'coffeevolume' column values to be between 0 and 1000\n",
    "expectation_suite_coffeevolume.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"coffeevolume\",\n",
    "            \"min_value\": 0,\n",
    "            \"max_value\": 1000,\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Loop through specified columns ('date', 'id', 'coffeevolume') and add expectations for null values\n",
    "for column in ['date', 'id', 'coffeevolume']:\n",
    "    expectation_suite_coffeevolume.add_expectation(\n",
    "        ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_values_to_be_null\",\n",
    "            kwargs={\n",
    "                \"column\": column,\n",
    "                \"mostly\": 0.0,\n",
    "            }\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6148b5e6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>\n",
    "As we have already installed Hopsworks in a previous cell, all we now need to do is import the library into this notebook, and start establishing the connection to the Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d98244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "\n",
    "#To connect to Managed:\n",
    "# import hsfs\n",
    "# conn = hsfs.connection(\n",
    "#     host=\"172f2800-9e76-11ee-ba4c-277d56d9f8e7.cloud.hopsworks.ai\",                                # DNS of your Feature Store instance\n",
    "#     project=\"RixCoffeevolumeDemo\",                      # Name of your Hopsworks Feature Store project\n",
    "#     hostname_verification=False,                     # Disable for self-signed certificates\n",
    "#     api_key_value=\"Q0sPuOSFpsuwdIa0.pfBCpgAAnPr3C3J49BvEdeJvfoqTkwQihEotXupzz23FPzDdJpexwHmXyRB8ACDf\"          # Feature store API key value \n",
    "# )\n",
    "# fs = conn.get_feature_store()           # Get the project's default feature store\"\n",
    "\n",
    "#To connect to Managed using environment variables:\n",
    "import hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a connection to the feature store (called `fs`) we can start working with it in the notebook. Specifically, we first want to start creating feature groups for our Coffee Consumption machine learning assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9471bceb",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Creating the **coffeevolume** Feature Group </span>\n",
    "Based on the synthetic data that we generated in previous notebook cells, we are now going to create the first feature group for our Coffee Volume dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'coffeevolume' feature group\n",
    "coffeevolume_fg = fs.get_or_create_feature_group(\n",
    "    name='coffeevolume',\n",
    "    description='Coffee Volume Consumption Data',\n",
    "    version=1,\n",
    "    primary_key=['id'],\n",
    "    event_time='date',\n",
    "    online_enabled=True,\n",
    "    expectation_suite=expectation_suite_coffeevolume,\n",
    ")    \n",
    "# Insert data\n",
    "coffeevolume_fg.insert(data_generated,write_options={\"wait\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done, we can move on to creating derived features that we will _engineer_ from the featuregroup above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad450b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è **coffeevolume** Feature Engineering  </span>\n",
    "\n",
    "In order to make predictions around the volume of the consumption of coffee that our hypothetical bar owner needs to take into account, we actually want to calculate a set of derived features that will be meaningful input to our prediction pipelines later on. We will therefore *engineer* the following features:\n",
    "\n",
    "- `ma_7`: This feature represents the **7-day moving average** of the 'coffeevolume' data, providing a smoothed representation of short-term coffeevolume trends.\n",
    "\n",
    "- `ma_14`: This feature represents the **14-day moving average** of the 'coffeevolume' data, offering a slightly longer-term smoothed coffeevolume trend.\n",
    "\n",
    "- `ma_30`: This feature represents the **30-day moving average** of the 'coffeevolume' data, providing a longer-term smoothed representation of coffeevolume trends.\n",
    "\n",
    "- `daily_rate_of_change`: This feature calculates the **daily rate of change** in coffee volumes as a percentage change, indicating how much the coffeevolume has changed from the previous day.\n",
    "\n",
    "- `volatility_30_day`: This feature measures the **volatility of coffee volume over a 30-day window** using the standard deviation. Higher values indicate greater coffee volume fluctuations.\n",
    "\n",
    "- `ema_02`: This feature calculates the **exponential moving average (EMA)** of 'coffeevolume' with a _smoothing factor of 0.2_, giving more weight to recent data points in the calculation.\n",
    "\n",
    "- `ema_05`: Similar to ema_02, this feature calculates the **EMA of 'coffee volume'** with a _smoothing factor of 0.5_, providing a different degree of responsiveness to recent data.\n",
    "\n",
    "- `rsi`: The **Relative Strength Index (RSI)** is a momentum oscillator that measures the speed and change of coffee volume movements. It ranges from 0 to 100, with values above 70 indicating higher-than-normal coffeevolume and values below 30 indicating lower-than-normal coffeevolume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3123547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the coffee volume data from the 'coffeevolume' feature group\n",
    "coffeevolume_df = coffeevolume_fg.read(online=True)\n",
    "coffeevolume_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate second-order features\n",
    "#coffeevolume_averages_df = calculate_second_order_features(coffeevolume_df)\n",
    "coffeevolume_averages_df = calculate_second_order_features(data_generated)\n",
    "\n",
    "# Display the first 3 rows of the resulting DataFrame\n",
    "coffeevolume_averages_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8496432",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Creating feature groups for the newly engineered features </span>\n",
    "\n",
    "Now that we have the newly engineered features calculated, we will add them to a separate set of Hopsworks Feature Groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create the 'averages' feature group\n",
    "coffeevolume_averages_fg = fs.get_or_create_feature_group(\n",
    "    name='coffeevolume_averages',\n",
    "    description='Calculated second coffeevolume order features',\n",
    "    version=1,\n",
    "    primary_key=['id'],\n",
    "    event_time='date',\n",
    "    online_enabled=True,\n",
    "    parents=[coffeevolume_fg],\n",
    ")\n",
    "# Insert data\n",
    "coffeevolume_averages_fg.insert(coffeevolume_averages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf0327",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
