{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to connect Neo4j to Hopsworks\n",
    "In this notebook we will\n",
    "* import data into Neo4j\n",
    "* use Neo4j's Graph Data Science library to calculate node2vec graph node embeddings, and store these on the nodes in the graph database.\n",
    "* read these embeddings into a dataframe\n",
    "* create feature groups in a Hopsworks feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing the data into Neo4j\n",
    "\n",
    "First we do a few Imports and set a few parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "URI = \"bolt://localhost:7687\"\n",
    "AUTH = (\"neo4j\", \"changeme\")\n",
    "DATABASE = \"gdshopsworksdemo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a few indexes in Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.execute_query(\"CREATE CONSTRAINT party_id_constraint FOR (p:Party) REQUIRE p.partyId IS UNIQUE\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE TEXT INDEX party_type_index FOR (p:Party) ON (p.partyType)\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE CONSTRAINT transaction_id_constraint FOR ()-[r:TRANSACTION]-() REQUIRE r.tran_id is UNIQUE\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE TEXT INDEX transaction_timestamp_index FOR ()-[r:TRANSACTION]-() ON r.tran_timestamp\", database_=DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do the first import of the first .csv file, holding the (:Party) nodes. This will finish very quickly, as there are only 7-8k nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=DATABASE) as session:\n",
    "            result = session.run(\"\"\"\n",
    "                load csv with headers from \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/party.csv\" as parties\n",
    "                create (p:Party)\n",
    "                set p = parties\n",
    "            \"\"\")\n",
    "print(result.consume().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the relationshops. There are approx 430k [:TRANSACTION] relationships, and importing these will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=DATABASE) as session:\n",
    "            result = session.run(\"\"\"\n",
    "                LOAD CSV WITH HEADERS FROM \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/transactions.csv\" AS Transaction\n",
    "                    MATCH (startNode:Party)\n",
    "                    WHERE startNode.partyId = Transaction.src\n",
    "                    CALL {\n",
    "                        WITH Transaction, startNode\n",
    "                        MATCH (endNode:Party)\n",
    "                        WHERE endNode.partyId = Transaction.dst\n",
    "                        CREATE (startNode)-[rel:TRANSACTION {tran_id: Transaction.tran_id, tx_type: Transaction.tx_type, base_amt: Transaction.base_amt, tran_timestamp: datetime(Transaction.tran_timestamp)}]->(endNode)\n",
    "                    } IN TRANSACTIONS OF 2500 ROWS;\n",
    "            \"\"\")\n",
    "print(result.consume().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the importing of the data into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculating the node embeddings in Neo4j\n",
    "This uses the GDS library of Neo4j, which has to be installed on the Neo4j server. We will be using the `node2vec` library to calculate the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    try:\n",
    "        gds = GraphDataScience(URI, auth=AUTH, database=DATABASE)\n",
    "        \n",
    "        # Uncomment this if you need to drop the `transaction_graph` from the gds catalog in memory\n",
    "        # gds.run_cypher(\n",
    "        #     \"\"\"\n",
    "        #     CALL gds.graph.drop('transaction_graph') YIELD graphName\n",
    "        #     \"\"\"\n",
    "        # )\n",
    "        gds.run_cypher(\n",
    "        \"\"\"\n",
    "        MATCH (p1:Party)-[t:TRANSACTION]->(p2:Party)\n",
    "            WHERE t.tran_timestamp >= datetime(\"2020-11-01\")\n",
    "                AND t.tran_timestamp < datetime(\"2020-12-01\")\n",
    "            RETURN p1, t, p2\n",
    "        \"\"\"\n",
    "        )\n",
    "        G, project_result = gds.graph.project(\"transaction_graph\", \"Party\", \"TRANSACTION\")\n",
    "        node2vec_result = gds.node2vec.write(\n",
    "            G,                                #  Graph object\n",
    "            embeddingDimension=10,\n",
    "            walkLength=80,\n",
    "            inOutFactor=1,\n",
    "            returnFactor=1,\n",
    "            writeProperty=\"node2vec\"\n",
    "        )\n",
    "        assert node2vec_result[\"nodePropertiesWritten\"] == G.node_count()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # further logging/processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: reading the embeddings from Neo4j, and storing them in the Hopsworks feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neo4j\n",
    "from tqdm import tqdm\n",
    "\n",
    "import hopsworks\n",
    "# Connecting to Hopsworks Serverless - need to choose project\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Connecting to Neo4j, getting the embeddings, and putting them into a dataframe\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    graph_embeddings_df = driver.execute_query(\n",
    "        \"\"\"MATCH (p:Party)-[t:TRANSACTION]->(:Party) \n",
    "            return \n",
    "            p.partyId as party_id, \n",
    "            p.partyType as party_type, \n",
    "            p.node2vec as party_graph_embedding, \n",
    "            datetime(t.tran_timestamp).epochmillis as timestamp\"\"\",\n",
    "        database_=DATABASE,\n",
    "        result_transformer_=neo4j.Result.to_df\n",
    "    )\n",
    "    print(type(graph_embeddings_df))  # <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "# Creating the features\n",
    "from hsfs import engine\n",
    "features = engine.get_instance().parse_schema_feature_group(graph_embeddings_df)\n",
    "for f in features:\n",
    "    if f.type == \"array<double>\" or f.type == \"array<float>\":\n",
    "        f.online_type = \"VARBINARY(20000)\"\n",
    "\n",
    "# Creating the feature group in Hopsworks Serverless App\n",
    "graph_embeddings_fg = fs.get_or_create_feature_group(name=\"graph_embeddings\",\n",
    "                                       version=1,\n",
    "                                       primary_key=[\"party_id\"],\n",
    "                                       description=\"node embeddings from transactions graph\",\n",
    "                                       event_time = 'timestamp',     \n",
    "                                       online_enabled=True,\n",
    "                                       features=features,\n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}\n",
    "                                       )\n",
    "graph_embeddings_fg.insert(graph_embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We now have our feature engineering based on Neo4j done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
