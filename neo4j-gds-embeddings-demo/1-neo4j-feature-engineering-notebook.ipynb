{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to connect Neo4j to Hopsworks\n",
    "In this notebook we will\n",
    "* import data into Neo4j\n",
    "* use Neo4j's Graph Data Science library to calculate node2vec graph node embeddings, and store these on the nodes in the graph database.\n",
    "* read these embeddings into a dataframe\n",
    "* create feature groups in a Hopsworks feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing the data into Neo4j\n",
    "\n",
    "First we do a few Imports and set a few parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience\n",
    "\n",
    "URI = \"bolt://localhost:7687\"\n",
    "AUTH = (\"neo4j\", \"changeme\")\n",
    "DATABASE = \"gdshopsworksdemo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a few indexes in Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.execute_query(\"CREATE CONSTRAINT party_id_constraint FOR (p:Party) REQUIRE p.partyId IS UNIQUE\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE TEXT INDEX party_type_index FOR (p:Party) ON (p.partyType)\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE CONSTRAINT transaction_id_constraint FOR ()-[r:TRANSACTION]-() REQUIRE r.tran_id is UNIQUE\", database_=DATABASE)\n",
    "    driver.execute_query(\"CREATE TEXT INDEX transaction_timestamp_index FOR ()-[r:TRANSACTION]-() ON r.tran_timestamp\", database_=DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do the first import of the first .csv file, holding the (:Party) nodes. This will finish very quickly, as there are only 7-8k nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/z0pz6z2j49g_bdh9zzznhvcr0000gp/T/ipykernel_992/2629808008.py:1: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=DATABASE) as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 7347, 'nodes_created': 7347, 'properties_set': 14694}\n"
     ]
    }
   ],
   "source": [
    "with driver.session(database=DATABASE) as session:\n",
    "            result = session.run(\"\"\"\n",
    "                load csv with headers from \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/party.csv\" as parties\n",
    "                create (p:Party)\n",
    "                set p = parties\n",
    "            \"\"\")\n",
    "print(result.consume().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import the relationshops. There are approx 430k [:TRANSACTION] relationships, and importing these will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/z0pz6z2j49g_bdh9zzznhvcr0000gp/T/ipykernel_992/3992007967.py:1: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=DATABASE) as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'relationships_created': 438386, 'properties_set': 1753544}\n"
     ]
    }
   ],
   "source": [
    "with driver.session(database=DATABASE) as session:\n",
    "            result = session.run(\"\"\"\n",
    "                LOAD CSV WITH HEADERS FROM \"https://repo.hops.works/master/hopsworks-tutorials/data/aml/transactions.csv\" AS Transaction\n",
    "                    MATCH (startNode:Party)\n",
    "                    WHERE startNode.partyId = Transaction.src\n",
    "                    CALL {\n",
    "                        WITH Transaction, startNode\n",
    "                        MATCH (endNode:Party)\n",
    "                        WHERE endNode.partyId = Transaction.dst\n",
    "                        CREATE (startNode)-[rel:TRANSACTION {tran_id: Transaction.tran_id, tx_type: Transaction.tx_type, base_amt: Transaction.base_amt, tran_timestamp: datetime(Transaction.tran_timestamp)}]->(endNode)\n",
    "                    } IN TRANSACTIONS OF 2500 ROWS;\n",
    "            \"\"\")\n",
    "print(result.consume().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the importing of the data into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculating the node embeddings in Neo4j\n",
    "This uses the GDS library of Neo4j, which has to be installed on the Neo4j server. We will be using the `node2vec` library to calculate the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    try:\n",
    "        gds = GraphDataScience(URI, auth=AUTH, database=DATABASE)\n",
    "        \n",
    "        # Uncomment this if you need to drop the `transaction_graph` from the gds catalog in memory\n",
    "        # gds.run_cypher(\n",
    "        #     \"\"\"\n",
    "        #     CALL gds.graph.drop('transaction_graph') YIELD graphName\n",
    "        #     \"\"\"\n",
    "        # )\n",
    "        gds.run_cypher(\n",
    "        \"\"\"\n",
    "        MATCH (p1:Party)-[t:TRANSACTION]->(p2:Party)\n",
    "            WHERE t.tran_timestamp >= datetime(\"2020-11-01\")\n",
    "                AND t.tran_timestamp < datetime(\"2020-12-01\")\n",
    "            RETURN p1, t, p2\n",
    "        \"\"\"\n",
    "        )\n",
    "        G, project_result = gds.graph.project(\"transaction_graph\", \"Party\", \"TRANSACTION\")\n",
    "        node2vec_result = gds.node2vec.write(\n",
    "            G,                                #  Graph object\n",
    "            embeddingDimension=10,\n",
    "            walkLength=80,\n",
    "            inOutFactor=1,\n",
    "            returnFactor=1,\n",
    "            writeProperty=\"node2vec\"\n",
    "        )\n",
    "        assert node2vec_result[\"nodePropertiesWritten\"] == G.node_count()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # further logging/processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: reading the embeddings from Neo4j, and storing them in the Hopsworks feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:UserWarning: The installed hopsworks client version 3.5.0rc1 may not be compatible with the connected Hopsworks backend version 3.4.1. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (3.4) by running 'pip install hopsworks==3.4.*'\n",
      "\n",
      "\n",
      "Multiple projects found. \n",
      "\n",
      "\t (1) rixdemo\n",
      "\t (2) BeerVolumePrediction\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/189590\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/189590/fs/189509/fg/551261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45683ee07e224c5d95de798b6bf35fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/438386 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: graph_embeddings_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/189590/jobs/named/graph_embeddings_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x13b1bde90>, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neo4j\n",
    "from tqdm import tqdm\n",
    "\n",
    "import hopsworks\n",
    "# Connecting to Hopsworks Serverless - need to choose project\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Connecting to Neo4j, getting the embeddings, and putting them into a dataframe\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    graph_embeddings_df = driver.execute_query(\n",
    "        \"\"\"MATCH (p:Party)-[t:TRANSACTION]->(:Party) \n",
    "            return \n",
    "            p.partyId as party_id, \n",
    "            p.partyType as party_type, \n",
    "            p.node2vec as party_graph_embedding, \n",
    "            datetime(t.tran_timestamp).epochmillis as timestamp\"\"\",\n",
    "        database_=DATABASE,\n",
    "        result_transformer_=neo4j.Result.to_df\n",
    "    )\n",
    "    print(type(graph_embeddings_df))  # <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "# Creating the features\n",
    "from hsfs import engine\n",
    "features = engine.get_instance().parse_schema_feature_group(graph_embeddings_df)\n",
    "for f in features:\n",
    "    if f.type == \"array<double>\" or f.type == \"array<float>\":\n",
    "        f.online_type = \"VARBINARY(20000)\"\n",
    "\n",
    "# Creating the feature group in Hopsworks Serverless App\n",
    "graph_embeddings_fg = fs.get_or_create_feature_group(name=\"graph_embeddings\",\n",
    "                                       version=1,\n",
    "                                       primary_key=[\"party_id\"],\n",
    "                                       description=\"node embeddings from transactions graph\",\n",
    "                                       event_time = 'timestamp',     \n",
    "                                       online_enabled=True,\n",
    "                                       features=features,\n",
    "                                       statistics_config={\"enabled\": False, \"histograms\": False, \"correlations\": False, \"exact_uniqueness\": False}\n",
    "                                       )\n",
    "graph_embeddings_fg.insert(graph_embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We now have our feature engineering based on Neo4j done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
