{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeerVolume Prediction Demo - Training Pipeline (2)\n",
    "\n",
    "This is the seocnd part of a short demonstration of how you can use Hopsworks for creating a Machine Learning System that creates predictions. The hypothetical use case is that of a **bar owner** who would want to predict how much beer will be consumed in his bar, based on past trends and behaviour.\n",
    "\n",
    "![](https://lh3.googleusercontent.com/blogger_img_proxy/ALY8t1uqu0YUTdfoFJYGV2r9a2iHEewpP3daVa9J3qzCzV3rZm8EX8YyhHhOHbfG450AhHYQXu6Hgf8pj2fTpSzg4uio4X_qv9TTEfMnEtO6rYLevnGBxF6sO97tGeYyzaAkGSyVBnw8WtWS1P_2RLY=s0-d)\n",
    "\n",
    "In this second part of the Machine Learning system that we are creating, we are going to focus on the **Training Pipeline** required to make the predictions that we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd6e7e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Code Library Imports and installations</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Supporting libraries\n",
    "We also need to install the Kaleido libraries so that we can use these during our notebook exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5b0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sklearn in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.0.post12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: hopsworks in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (3.4.3)\n",
      "Requirement already satisfied: hsfs<3.5.0,>=3.4.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.4.4)\n",
      "Requirement already satisfied: hsml<3.5.0,>=3.4.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (3.4.3)\n",
      "Requirement already satisfied: pyhumps==1.6.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (1.6.1)\n",
      "Requirement already satisfied: requests in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (2.31.0)\n",
      "Requirement already satisfied: furl in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (2.1.3)\n",
      "Requirement already satisfied: boto3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (1.28.83)\n",
      "Requirement already satisfied: pyjks in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (20.0.0)\n",
      "Requirement already satisfied: mock in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (5.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hopsworks) (4.66.1)\n",
      "Requirement already satisfied: pandas<2.1.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.26.1)\n",
      "Requirement already satisfied: avro==1.11.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.11.0)\n",
      "Requirement already satisfied: sqlalchemy in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.0.23)\n",
      "Requirement already satisfied: PyMySQL[rsa] in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.1.0)\n",
      "Requirement already satisfied: great-expectations==0.14.13 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.14.13)\n",
      "Requirement already satisfied: markupsafe<2.1.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.0.1)\n",
      "Requirement already satisfied: tzlocal in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.2)\n",
      "Requirement already satisfied: fsspec in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.10.0)\n",
      "Requirement already satisfied: altair<5,>=4.0.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.2.2)\n",
      "Requirement already satisfied: Click>=7.1.2 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.4.3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=3.2 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (41.0.5)\n",
      "Requirement already satisfied: dataclasses in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.6)\n",
      "Requirement already satisfied: importlib-metadata>=1.7.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (6.8.0)\n",
      "Requirement already satisfied: Ipython>=7.16.3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (8.17.2)\n",
      "Requirement already satisfied: jinja2<3.1.0,>=2.10 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.3)\n",
      "Requirement already satisfied: jsonpatch>=1.22 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.33)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.19.2)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.2)\n",
      "Requirement already satisfied: nbformat>=5.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.9.2)\n",
      "Requirement already satisfied: packaging in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (23.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2021.3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.3.post1)\n",
      "Requirement already satisfied: ruamel.yaml<0.17.18,>=0.16 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.17.17)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.11.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.26.18)\n",
      "Requirement already satisfied: pyhopshive[thrift] in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.6.4.1.dev0)\n",
      "Requirement already satisfied: pyarrow>=10.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (14.0.1)\n",
      "Requirement already satisfied: confluent-kafka<=2.1.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.1.1)\n",
      "Requirement already satisfied: fastavro<=1.8.2,>=1.4.11 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->hopsworks) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->hopsworks) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->hopsworks) (2023.7.22)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.83 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->hopsworks) (1.31.83)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from boto3->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: six>=1.8.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from furl->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from furl->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: javaobj-py3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyjks->hopsworks) (0.4.3)\n",
      "Requirement already satisfied: pyasn1>=0.3.5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyjks->hopsworks) (0.5.0)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: pycryptodomex in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyjks->hopsworks) (3.19.0)\n",
      "Requirement already satisfied: twofish in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pandas<2.1.0->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.3)\n",
      "Requirement already satisfied: future in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.18.3)\n",
      "Requirement already satisfied: thrift>=0.10.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from sqlalchemy->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.1)\n",
      "Requirement already satisfied: entrypoints in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from altair<5,>=4.0.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.4)\n",
      "Requirement already satisfied: toolz in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from altair<5,>=4.0.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.12.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from cryptography>=3.2->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from importlib-metadata>=1.7.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.17.0)\n",
      "Requirement already satisfied: decorator in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.13.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jsonpatch>=1.22->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jsonschema>=2.5.1->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.12.0)\n",
      "Requirement already satisfied: fastjsonschema in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.18.1)\n",
      "Requirement already satisfied: jupyter-core in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (5.5.0)\n",
      "Requirement already satisfied: pycparser in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jedi>=0.16->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pexpect>4.3->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.2.9)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jupyter-core->nbformat>=5.0->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (3.11.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/rvanbruggen/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.14.13->hsfs<3.5.0,>=3.4.0->hsfs[python]<3.5.0,>=3.4.0->hopsworks) (0.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U kaleido # For Plotly Image export\n",
    "!pip install sklearn\n",
    "!pip install hopsworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other imports\n",
    "We are importing a number of other libaries, among which several classes from  `beervolume.py` and `averages.py`, into this notebook, as we will use it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8355be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import joblib\n",
    "from beervolume import plot_prediction_test\n",
    "from functions import predict_id\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbea0ad",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>\n",
    "As we have already installed Hopsworks on this system, all we now need to do is import the library into this notebook, and start establishing the connection to the Hopsworks feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e499f528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "#To connect to Managed:\n",
    "import hsfs\n",
    "conn = hsfs.connection(\n",
    "    host=\"172f2800-9e76-11ee-ba4c-277d56d9f8e7.cloud.hopsworks.ai\",                                # DNS of your Feature Store instance\n",
    "    project=\"RixBeervolumeDemo\",                      # Name of your Hopsworks Feature Store project\n",
    "    hostname_verification=False,                     # Disable for self-signed certificates\n",
    "    api_key_value=\"Q0sPuOSFpsuwdIa0.pfBCpgAAnPr3C3J49BvEdeJvfoqTkwQihEotXupzz23FPzDdJpexwHmXyRB8ACDf\"          # Feature store API key value \n",
    ")\n",
    "fs = conn.get_feature_store()           # Get the project's default feature store\"\n",
    "\n",
    "#To connect to Serverless:\n",
    "#import hopsworks\n",
    "#project = hopsworks.login()\n",
    "#fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already created the necessary feature groups in our previous notebook, we can now just import these into our training pipeline. Remember we had two feature groups:\n",
    "1. a `beervolume` feature group that contained the synthetic data that we had created,\n",
    "2. a `beervolume_averages` feature group that contained a number of _engineered_ features that we derived from the `beervolume` feature group in order to have better predictions later on.\n",
    "\n",
    "We retrieve bother feature groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c6c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "beervolume_fg = fs.get_feature_group(\n",
    "    name='beervolume',\n",
    "    version=1,\n",
    ")\n",
    "beervolume_averages_fg = fs.get_feature_group(\n",
    "    name='beervolume_averages',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72db48",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üî™ Preparing our Training pipeline: Feature Selection </span>\n",
    "Using the Hopsworks feature store, we can very easily select the specific subset that we need for our training pipeline, and be confident that we will be using the correct training dataset in our Machine Learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0740ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (16.23s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>beervolume</th>\n",
       "      <th>ma_7</th>\n",
       "      <th>ma_14</th>\n",
       "      <th>ma_30</th>\n",
       "      <th>daily_rate_of_change</th>\n",
       "      <th>volatility_30_day</th>\n",
       "      <th>ema_02</th>\n",
       "      <th>ema_05</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>0</td>\n",
       "      <td>199.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.833333</td>\n",
       "      <td>199.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>201.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.516393</td>\n",
       "      <td>200.771429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>202.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.154472</td>\n",
       "      <td>201.640000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>0</td>\n",
       "      <td>206.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.173913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.833889</td>\n",
       "      <td>204.303226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  id  beervolume  ma_7  ma_14  ma_30  daily_rate_of_change  \\\n",
       "0  2023-09-01   0       200.0   0.0    0.0    0.0              0.000000   \n",
       "1  2023-09-02   0       199.7   0.0    0.0    0.0             -0.150000   \n",
       "2  2023-09-04   0       201.5   0.0    0.0    0.0              0.901352   \n",
       "3  2023-09-05   0       202.4   0.0    0.0    0.0              0.446650   \n",
       "4  2023-09-07   0       206.8   0.0    0.0    0.0              2.173913   \n",
       "\n",
       "   volatility_30_day      ema_02      ema_05  rsi  \n",
       "0                0.0  200.000000  200.000000  0.0  \n",
       "1                0.0  199.833333  199.800000  0.0  \n",
       "2                0.0  200.516393  200.771429  0.0  \n",
       "3                0.0  201.154472  201.640000  0.0  \n",
       "4                0.0  202.833889  204.303226  0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for training dataset\n",
    "query = beervolume_fg.select_all() \\\n",
    "    .join(beervolume_averages_fg.select_except(['date']))\n",
    "query.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334a4cb",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü§ñ Preparing our Training pipeline: Transformation Functions </span>\n",
    "Using the Hopsworks feature store, we can easily apply a set of transformation functions that will apply to our training pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bccb7d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ma_7': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'ma_14': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'ma_30': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'daily_rate_of_change': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'volatility_30_day': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'ema_02': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'ema_05': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>,\n",
       " 'rsi': <hsfs.transformation_function.TransformationFunction at 0x15e7c53d0>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load transformation function\n",
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "\n",
    "# Define a list of feature names\n",
    "feature_names = [\n",
    "    'ma_7', 'ma_14', 'ma_30', 'daily_rate_of_change', 'volatility_30_day', 'ema_02', 'ema_05', 'rsi'\n",
    "]\n",
    "\n",
    "# Map features to transformations\n",
    "transformation_functions = {\n",
    "    feature_name: min_max_scaler\n",
    "    for feature_name in feature_names\n",
    "}\n",
    "transformation_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ad679",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation leveraging feature groups, feature selection and feature transformations </span>\n",
    "Using the feature groups, the selection that we made above and finally the associated transformation functions, we can create a **feature view** in the Hopsworks feature store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffdfda5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingDatasetFeature.__init__() got an unexpected keyword argument 'inference_helper_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get or create the 'beervolume_fv' feature view\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feature_view \u001b[38;5;241m=\u001b[39m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_feature_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeervolume_fv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeervolume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformation_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformation_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/feature_store.py:1502\u001b[0m, in \u001b[0;36mFeatureStore.get_or_create_feature_view\u001b[0;34m(self, name, query, version, description, labels, transformation_functions)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get feature view metadata object or create a new one if it doesn't exist. This method doesn't update\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;124;03mexisting feature view metadata object.\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;124;03m    `FeatureView`: The feature view metadata object.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mRestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1505\u001b[0m         e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270181\u001b[39m\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m\n\u001b[1;32m   1507\u001b[0m     ):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/core/feature_view_engine.py:96\u001b[0m, in \u001b[0;36mFeatureViewEngine.get\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version:\n\u001b[0;32m---> 96\u001b[0m         fv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_view_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattach_transformation_function(fv)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/core/feature_view_api.py:100\u001b[0m, in \u001b[0;36mFeatureViewApi.get_by_name_version\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     98\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path \u001b[38;5;241m+\u001b[39m [name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_VERSION, version]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureView\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m270009\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/feature_view.py:2407\u001b[0m, in \u001b[0;36mFeatureView.from_response_json\u001b[0;34m(cls, json_dict)\u001b[0m\n\u001b[1;32m   2405\u001b[0m features \u001b[38;5;241m=\u001b[39m json_decamelized\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n\u001b[0;32m-> 2407\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_dataset_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingDatasetFeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature\u001b[49m\n\u001b[1;32m   2410\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2413\u001b[0m fv\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m   2414\u001b[0m fv\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [feature\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features \u001b[38;5;28;01mif\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mlabel]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/feature_view.py:2408\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2405\u001b[0m features \u001b[38;5;241m=\u001b[39m json_decamelized\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features:\n\u001b[1;32m   2407\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 2408\u001b[0m         \u001b[43mtraining_dataset_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingDatasetFeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_response_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature\u001b[49m\n\u001b[1;32m   2410\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2411\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[1;32m   2412\u001b[0m     ]\n\u001b[1;32m   2413\u001b[0m fv\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m   2414\u001b[0m fv\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m [feature\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features \u001b[38;5;28;01mif\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mlabel]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/hsfs/training_dataset_feature.py:65\u001b[0m, in \u001b[0;36mTrainingDatasetFeature.from_response_json\u001b[0;34m(cls, json_dict)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_response_json\u001b[39m(\u001b[38;5;28mcls\u001b[39m, json_dict):\n\u001b[1;32m     64\u001b[0m     json_decamelized \u001b[38;5;241m=\u001b[39m humps\u001b[38;5;241m.\u001b[39mdecamelize(json_dict)\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjson_decamelized\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingDatasetFeature.__init__() got an unexpected keyword argument 'inference_helper_column'"
     ]
    }
   ],
   "source": [
    "# Get or create the 'beervolume_fv' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='beervolume_fv',\n",
    "    version=1,\n",
    "    query=query,\n",
    "    labels=[\"beervolume\"],\n",
    "    transformation_functions=transformation_functions,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e1170",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset Creation based on the Feature View</span>\n",
    "The next part of our process will focus on the creation of a Training dataset based on the feature view that we have prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554cbace",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_view' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get training and testing sets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_view\u001b[49m\u001b[38;5;241m.\u001b[39mtrain_test_split(\n\u001b[1;32m      3\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeer Volume Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Provide a description for the dataset split\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     train_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-09-01\u001b[39m\u001b[38;5;124m'\u001b[39m,      \u001b[38;5;66;03m# Start date for the training set\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     train_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-11-01\u001b[39m\u001b[38;5;124m'\u001b[39m,        \u001b[38;5;66;03m# End date for the training set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     test_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-11-01\u001b[39m\u001b[38;5;124m'\u001b[39m,       \u001b[38;5;66;03m# Start date for the testing set\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     test_end\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# End date for the testing set (current date)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_view' is not defined"
     ]
    }
   ],
   "source": [
    "# Get training and testing sets\n",
    "X_train, X_test, y_train, y_test = feature_view.train_test_split(\n",
    "    description='Beer Volume Dataset',  # Provide a description for the dataset split\n",
    "    train_start='2023-09-01',      # Start date for the training set\n",
    "    train_end='2023-11-01',        # End date for the training set\n",
    "    test_start='2023-11-01',       # Start date for the testing set\n",
    "    test_end=datetime.today().strftime(\"%Y-%m-%d\"),  # End date for the testing set (current date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041666ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7315f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af817399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the training features by the 'date' column\n",
    "X_train = X_train.sort_values(\"date\")\n",
    "\n",
    "# Reindex the target 'y_train' to match the sorted order of 'X_train'\n",
    "y_train = y_train.reindex(X_train.index)\n",
    "\n",
    "# Sort the testing features by the 'date' column\n",
    "X_test = X_test.sort_values(\"date\")\n",
    "\n",
    "# Reindex the target 'y_test' to match the sorted order of 'X_test'\n",
    "y_test = y_test.reindex(X_test.index)\n",
    "\n",
    "# Extract and store the 'date' column as a separate DataFrame for both training and testing sets\n",
    "train_date = pd.DataFrame(X_train.pop(\"date\"))\n",
    "test_date = pd.DataFrame(X_test.pop(\"date\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d0253",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\">üß¨ Using the training dataset to create a Machine Learning Model</span>\n",
    "\n",
    "In order to now create a predictive model out of our data, we will use the **XGBoost Regressor** to examine the training dataset and figure out a predictive model. XGBoost regressor is a powerful and highly effective machine learning algorithm for regression problems. XGBoost is known for its ability to handle complex relationships in the data, handle missing values, and provide accurate predictions. It's a popular choice in the data science community due to its robustness and excellent predictive performance, making it well-suited for our specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE on the validation set\n",
    "mse = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for a specific ID (ID=1) using the 'predict_id' function\n",
    "prediction_for_id = predict_id(\n",
    "    1, \n",
    "    X_test, \n",
    "    model,\n",
    ")\n",
    "\n",
    "# Generate a Plotly figure for visualizing the predictions\n",
    "fig = plot_prediction_test(\n",
    "    1, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    train_date, \n",
    "    test_date, \n",
    "    prediction_for_id,\n",
    ")\n",
    "\n",
    "# Display the generated Plotly figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558799fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Creating the Model Schema </span>\n",
    "Now that we know what the input training features and the target/output variables will look like, we can create a schema for this and save this to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b490e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Create an input schema using the training features\n",
    "input_schema = Schema(X_train.values)\n",
    "\n",
    "# Create an output schema using the target variable\n",
    "output_schema = Schema(y_train)\n",
    "\n",
    "# Create a model schema using the input and output schemas\n",
    "model_schema = ModelSchema(\n",
    "    input_schema=input_schema, \n",
    "    output_schema=output_schema,\n",
    ")\n",
    "\n",
    "# Convert the model schema to a dictionary\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8f511",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Registering the model in the Hopsworks registry</span>\n",
    "We will also save and persist the model in Hopsworks, in case future decisions would need to be retraced to a specific version of the prediction system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory for saving the model\n",
    "model_dir = \"beervolume_model\"\n",
    "\n",
    "# Check if the directory exists, and create it if not\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the trained XGBoost model using joblib\n",
    "joblib.dump(model, f'{model_dir}/xgboost_beervolume_model.pkl')\n",
    "\n",
    "# Write the generated Plotly figure image to the specified directory\n",
    "fig.write_image(f'{model_dir}/model_prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model registry from the project\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model in the model registry named 'xgboost_price_model'\n",
    "price_model = mr.python.create_model(\n",
    "    name=\"xgboost_beervolume_model\", \n",
    "    metrics={\"MSE\": mse},           # Specify metrics (Mean Squared Error)\n",
    "    model_schema=model_schema,      # Provide the model schema\n",
    "    input_example=X_train.sample(), # Provide an example of the input data\n",
    "    description=\"Beervolume Predictor\",  # Add a description for the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified directory\n",
    "beervolume_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfb99f",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ff5f27\">üöÄ Beervolume Consumption Prediction Model Deployment</span>\n",
    "\n",
    "**About Model Serving**\n",
    "\n",
    "Models can be served via KFServing or \"default\" serving, which means a Docker container exposing a Flask server. For KFServing models, or models written in Tensorflow, we do not need to write a prediction file. However, for sklearn models using default serving, you do need to proceed to write a prediction file.\n",
    "\n",
    "We will not go into this at this point - and wrap up the 2nd part of our prediction system with this training example.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017c8e4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìé Predictor script for Python models</span>\n",
    "\n",
    "Scikit-learn and XGBoost models are deployed as Python models, in which case you need to provide a Predict class that implements the predict method. The `predict()` method invokes the model on the inputs and returns the prediction as a list.\n",
    "\n",
    "The `init()` method is run when the predictor is loaded into memory, loading the model from the local directory it is materialized to, ARTIFACT_FILES_PATH.\n",
    "\n",
    "The directive **\"%%writefile\"** writes out the cell before to the given Python file. We will use the **predict_example.py** file to create a deployment for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a97ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hsfs\n",
    "import joblib\n",
    "\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the serving state, reads a trained model\"\"\"        \n",
    "        # get feature store handle\n",
    "        fs_conn = hsfs.connection()\n",
    "        self.fs = fs_conn.get_feature_store()\n",
    "        \n",
    "        # get feature view\n",
    "        self.fv = self.fs.get_feature_view(\"beervolume_fv\", 1)\n",
    "        \n",
    "        # initialize serving\n",
    "        self.fv.init_serving(1)\n",
    "\n",
    "        # load the trained model\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/xgboost_beervolume_model.pkl\")\n",
    "        print(\"Initialization of Beervolume model Complete\")\n",
    "\n",
    "    \n",
    "    def predict(self, id_value):\n",
    "        \"\"\" Serves a Beervolume prediction request usign a trained model\"\"\"\n",
    "        # Retrieve feature vectors\n",
    "        feature_vector = self.fv.get_feature_vector(\n",
    "            entry = {'id': id_value[0]}\n",
    "        )\n",
    "        return self.model.predict(np.asarray(feature_vector[1:]).reshape(1, -1)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979582c",
   "metadata": {},
   "source": [
    "This script needs to be put into a known location in the Hopsworks file system. Let's call the file predict_example.py and put it in the Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64048e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset API from the project\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "# Upload the file \"predict_example.py\" to the \"Models\" dataset, overwriting if it already exists\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "\n",
    "# Create the full path to the uploaded predictor script\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cea10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59ec95",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üöÄ Create the deployment</span>\n",
    "\n",
    "Here, you fetch the model you want from the model registry and define a configuration for the deployment. For the configuration, you need to specify the serving type (default or KFserving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the 'beervolume_model'\n",
    "deployment = beervolume_model.deploy(\n",
    "    name=\"beervolumeonlinemodeldeployment\",  # Specify the deployment name\n",
    "    script_file=predictor_script_path,  # Provide the path to the predictor script\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86154683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the deployment and wait for it up to 180 seconds\n",
    "deployment.start(await_running=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current state of the deployment and describe it\n",
    "deployment_state = deployment.get_state().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea906d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict price for the 1 ID\n",
    "deployment.predict({'instances': [1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354c27a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
